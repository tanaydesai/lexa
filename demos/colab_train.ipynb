{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViFd1jdOULJa",
        "outputId": "d2f69371-3277-4617-f89e-e2abf8f8618d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.17.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from transformers import AutoTokenizer\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "8MX4VvOJNun6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configdict= {\n",
        "    \"gpt-1M\":{\n",
        "        \"batch_size\": 64,\n",
        "        \"block_size\": 256,\n",
        "        \"max_pos_n_embed\": 2048,\n",
        "        \"lr\": 2e-3,\n",
        "        \"n_layer\": 8,\n",
        "        \"n_head\": 16,\n",
        "        \"n_embed\": 64,\n",
        "        \"dropout\": 0.2,\n",
        "        \"epochs\": 1,\n",
        "        \"eval_interval\": 200,\n",
        "        \"eval_steps\": 50,\n",
        "        \"n\": 1200000,\n",
        "        \"k\": 7999,\n",
        "        \"vocab_size\": 8000,\n",
        "    },\n",
        "    \"gpt-15M\":{\n",
        "        \"batch_size\": 64,\n",
        "        \"block_size\": 256,\n",
        "        \"max_pos_n_embed\": 2048,\n",
        "        \"lr\": 2e-3,\n",
        "        \"n_layer\": 8,\n",
        "        \"n_head\": 16,\n",
        "        \"n_embed\": 320,\n",
        "        \"dropout\": 0.2,\n",
        "        \"epochs\": 1,\n",
        "        \"eval_interval\": 200,\n",
        "        \"eval_steps\": 50,\n",
        "        \"n\": 1200000,\n",
        "        \"k\": 7999,\n",
        "        \"vocab_size\": 8000,\n",
        "    },\n",
        "     \"tokenizer\":{\n",
        "        \"name\": \"EleutherAI/gpt-neo-125M\",\n",
        "    },\n",
        "    \"data\":{\n",
        "        \"name\": \"roneneldan/TinyStories\",\n",
        "    },\n",
        "}\n",
        "\n",
        "class Config:\n",
        "    def __init__(self, dictionary):\n",
        "        for key, value in dictionary.items():\n",
        "            if isinstance(value, dict):\n",
        "                setattr(self, key, Config(value))\n",
        "            else:\n",
        "                setattr(self, key, value)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self.__dict__[key]\n",
        "\n",
        "config = Config(configdict)"
      ],
      "metadata": {
        "id": "VzI7szuBN_O6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self, config, k=None, file_path=None, device=\"cpu\"):\n",
        "    self.k = k\n",
        "    self.file_path = file_path\n",
        "    self.device = device\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(config.name)\n",
        "    self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "    self.vocab_size = self.tokenizer.vocab_size if not self.k else self.k\n",
        "    self.initialize()\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        \"initl_vocab_size\": self.tokenizer.vocab_size,\n",
        "        \"final_vocab_size\": self.vocab_size,\n",
        "        \"vocab_size\": self.vocab_size,\n",
        "        \"total_tokens\": self.total_tokens,\n",
        "        \"total_tokens_used\": self.tokens_used if self.k else self.total_tokens,\n",
        "        \"total_unsed_tokens\": self.total_tokens - self.tokens_used if self.k else 0\n",
        "    }\n",
        "    return config\n",
        "\n",
        "  def initialize(self):\n",
        "    with open(self.file_path, 'r') as file:\n",
        "      tokens_counts = json.load(file)\n",
        "\n",
        "    self.total_tokens = sum(tokens_counts.values()) # Already sorted\n",
        "\n",
        "    if self.k:\n",
        "      self.tokens_used = sum([i for i in tokens_counts.values()][:self.k])\n",
        "      self.top_k_tokens = [i for i in tokens_counts.keys()][:self.k]# We will only use top k tokens, others will be ignored\n",
        "      self.top_k_tokens.append(\"50256\")\n",
        "      self.vocab_size +=1\n",
        "      self.top_k_tokens_dict =  {token: index for index, token in enumerate(self.top_k_tokens)}\n",
        "      self.reversed_top_k_tokens_dict = {value: int(key) for key, value in self.top_k_tokens_dict.items()}\n",
        "\n",
        "\n",
        "  def encoder(self, input, padding=False, max_length=256, truncation=False):\n",
        "    tokens = self.tokenizer(input , return_tensors='pt', padding=padding, max_length=max_length, truncation=truncation)['input_ids'].to(self.device)\n",
        "\n",
        "    if self.k:\n",
        "      tokens = torch.tensor([self.top_k_tokens_dict.get(str(token.item()), self.top_k_tokens_dict[\"50256\"]) for token in tokens.view(-1)], device=self.device).view(tokens.shape)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "  def decoder(self, tokens):\n",
        "    if self.k:\n",
        "      tokens = torch.tensor([[self.reversed_top_k_tokens_dict[token.item()] for token in row] for row in tokens], device=tokens.device)\n",
        "\n",
        "    output = [self.tokenizer.decode(x, skip_special_tokens=True) for x in tokens]\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "D-1iBIRuNw1U"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Qs3xzFTyNjZH"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self, config, head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(config.n_embed, head_size, bias=False)\n",
        "    self.query = nn.Linear(config.n_embed, head_size, bias=False)\n",
        "    self.value = nn.Linear(config.n_embed, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(config.block_size, config.block_size)))  # (T, T)\n",
        "    self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "    k = self.key(x) # (B, T, C)\n",
        "    q = self.query(x) # (B, T, C)\n",
        "    wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5 # (B, T, C) X (B, C, T) --> (B, T, T)\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "    wei = self.dropout(wei)\n",
        "    v = self.value(x)  # (B,T,C)\n",
        "    out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "    return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, config, head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(config, head_size) for _ in range(config.n_head)])\n",
        "    self.proj  = nn.Linear(head_size * config.n_head, config.n_embed)\n",
        "    self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = torch.concat([h(x) for h in self.heads], dim=-1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "   super().__init__()\n",
        "   self.layers = nn.Sequential(\n",
        "        nn.Linear(config.n_embed, 4 * config.n_embed),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(4 * config.n_embed, config.n_embed),\n",
        "        nn.Dropout(config.dropout),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    head_size = config.n_embed // config.n_head\n",
        "    self.sa_heads = MultiHeadAttention(config, head_size)\n",
        "    self.ffwd = FeedForward(config)\n",
        "    self.ln1 = nn.LayerNorm(config.n_embed)\n",
        "    self.ln2 = nn.LayerNorm(config.n_embed)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.sa_heads(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x\n",
        "\n",
        "\n",
        "class GPT2(nn.Module):\n",
        "  def __init__(self, config, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.block_size = config.block_size\n",
        "    self.embedings = nn.Embedding(config.vocab_size, config.n_embed)\n",
        "    self.position_embedings = nn.Embedding(config.max_pos_n_embed, config.n_embed)\n",
        "    self.dropout = nn.Dropout(config.dropout)\n",
        "    self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n",
        "    self.ln_final = nn.LayerNorm(config.n_embed)\n",
        "    self.lm_head = nn.Linear(config.n_embed, config.vocab_size)\n",
        "\n",
        "  def get_parameters(self):\n",
        "    return sum(p.numel() for p in self.parameters())\n",
        "\n",
        "  def save(self, path):\n",
        "    torch.save(self.state_dict(), path)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    B, T = idx.shape\n",
        "    token_embed = self.embedings(idx) # (B, T, C)\n",
        "    position_embed = self.position_embedings(torch.arange(T,  device=self.device)) # (T, C)\n",
        "    x = token_embed + position_embed # (B, T, C)\n",
        "    x = self.dropout(x) # (B, T, C)\n",
        "    x = self.blocks(x) # (B, T, C)\n",
        "    x = self.ln_final(x) # (B, T, C)\n",
        "    logits = self.lm_head(x)  # (B, T, vocab_size)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      logits = logits[..., :-1, :].contiguous()\n",
        "      loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets[..., 1:].contiguous().view(-1), ignore_index=50256)\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_tokens, temperature=1.0, top_k=None):\n",
        "    # idx is (B, T)\n",
        "    for _ in range(max_tokens):\n",
        "      idx_cond = idx[:, -self.block_size:]\n",
        "      logits, _ = self(idx_cond) # (B, T, C)\n",
        "      logits = logits[:, -1, :]  / temperature # (B, C)\n",
        "      if top_k is not None:\n",
        "        v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "        logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "      probs = F.softmax(logits, dim=-1) # Softmax Independently for C dim\n",
        "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      idx = torch.concat((idx, idx_next), dim=1) # (B, T+1)\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(config, batch_size, n, device='cpu'):\n",
        "    dataset = load_dataset(config.name)\n",
        "    train_data = DataLoader(dataset[\"train\"][:n][\"text\"], batch_size=batch_size, shuffle=True, pin_memory=True, pin_memory_device=device)\n",
        "    val_data = DataLoader(dataset[\"validation\"][:n][\"text\"], batch_size=batch_size, shuffle=True, pin_memory=True, pin_memory_device=device)\n",
        "\n",
        "    return train_data, val_data\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, train_data, val_data, encoder, eval_steps=50):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_steps)\n",
        "        for k in range(eval_steps):\n",
        "            data = train_data if split == 'train' else val_data\n",
        "            tokens = encoder(next(iter(data))[0], max_length=model.block_size, padding=\"max_length\", truncation=True)\n",
        "            _, loss = model(tokens, tokens)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "def plot_losses(losses):\n",
        "    train_losses = [o['train'] for o in losses if o.get('train') is not None]\n",
        "    valid_losses = [o['valid'] for o in losses if o.get('valid') is not None]\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(valid_losses, label='Validation Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Losses')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Te4z0L9_UIK8"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "  def __init__(self, config, model, optimizer, train_data, val_data, encoder):\n",
        "    self.config = config\n",
        "    self.model = model\n",
        "    self.optimizer = optimizer\n",
        "    self.train_data = train_data\n",
        "    self.val_data = val_data\n",
        "    self.encoder = encoder\n",
        "\n",
        "  def train(self, epochs, eval_interval=200, eval_steps=50):\n",
        "    max_steps = epochs * round(self.config.n / self.config.batch_size)\n",
        "    steps = 0\n",
        "    tracked_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      print(f\"Starting Epoch: {epoch + 1} {'-' * 100}\")\n",
        "      for batch in self.train_data:\n",
        "        if steps % eval_interval == 0 or steps == max_steps-1:\n",
        "          losses = estimate_loss(self.model, self.train_data, self.val_data, self.encoder, eval_steps)\n",
        "          tracked_losses.append(losses)\n",
        "          print(f\"Epoch: {epoch + 1}/{epochs} | Step: {steps}/{max_steps} | Train loss: {losses['train']:.4f} | Val loss: {losses['val']:.4f}\")\n",
        "\n",
        "        tokens = self.encoder(batch, max_length=self.config.block_size, padding=\"max_length\", truncation=True)\n",
        "        _, loss = self.model(tokens, tokens)\n",
        "        self.optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        steps += 1\n",
        "\n",
        "    return tracked_losses"
      ],
      "metadata": {
        "id": "6TeolShMUDdF"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_name= \"gpt-1M\"\n",
        "model_config = config[model_name]\n",
        "\n",
        "train_data, val_data = load_data(config.data, model_config.batch_size, 64, device=device)\n",
        "tokenizer = Tokenizer(config.tokenizer, k=model_config.k, file_path=\"tokens.json\", device=device)\n",
        "\n",
        "model = GPT2(model_config, device=device)\n",
        "model = model.to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=model_config.lr)\n",
        "\n",
        "trainer = Trainer(model_config, model, optim, train_data, val_data, tokenizer.encoder)\n",
        "tracked_losses = trainer.train(epochs=1, eval_interval=200, eval_steps=50)\n",
        "model.save(\"model-1M.pth\")\n",
        "\n",
        "print(tokenizer.get_config())\n",
        "plot_losses(tracked_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "bKE8fCpIUPhn",
        "outputId": "aa0cde46-197c-45f0-fb55-ca6d133bb3ed"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
            "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Epoch: 1 ----------------------------------------------------------------------------------------------------\n",
            "Epoch: 1/1 | Step: 0/18750 | Train loss: 9.0884 | Val loss: 9.0914\n",
            "{'initl_vocab_size': 50257, 'final_vocab_size': 8000, 'vocab_size': 8000, 'total_tokens': 476616445, 'total_tokens_used': 475526033, 'total_unsed_tokens': 1090412}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}